predictor: 
  model_cfg: 
    name: dualtrack_fusion_model
    global_encoder_cfg: 
      name: global_encoder_cnn
      max_position_embeddings: 4096
      max_seq_length: 4096
    local_encoder_cfg: 
      name: dualtrack_loc_enc_stg3_legacy
      backbone_cfg:
        max_subsequence_size: 1024 # lower to 512 to reduce memory footprint
      max_position_embeddings: 4096
      freeze_backbone: true
      use_cache: true
    max_position_embeddings: 4096
    load_kw: 
      strict: false
      handle_size_mismatch: true
    checkpoint: data/checkpoints/dualtrack_ft.pt 

  preprocessing: 
    name: glob_loc
    run_preprocessing_on_compute_device: true # this speeds up preprocessing but could consume gpu memory

  device: cuda
  precision: fp16 # <---- saves time and memory but could cost in performance

ddf_device: ${predictor.device}